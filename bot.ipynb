{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import talib\n",
    "import quandl\n",
    "from copy import deepcopy\n",
    "import optuna\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, log_loss\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BTC/USDの日足を取得\n",
    "df = quandl.get('BCHAIN/MKPRU')\n",
    "date = df.index\n",
    "v = np.array(df['Value'])\n",
    "v = v[v > 0]\n",
    "train, test = v[:-300], v[-300:]\n",
    "\n",
    "def getTrain(data):\n",
    "    return data[:-300]\n",
    "\n",
    "def getTest(data):\n",
    "    return data[-300:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 分足を取得\n",
    "df = {}\n",
    "for freq in ['15m', '1h', '2h', '4h', '8h', '12h', '1d']:\n",
    "    df[freq] = pd.read_csv('bitcoincharts-ohlcv/scripts/bitflyerJPY_{0}.csv'.format(freq), names=('DATE', 'OPEN', 'HIGH', 'LOW', 'CLOSE', 'VOLUME'), \n",
    "                dtype={'OPEN': np.float, 'HIGH': np.float, 'LOW': np.float, 'CLOSE': np.float, 'VOLUME': np.float}, \n",
    "                parse_dates=[0])\n",
    "\n",
    "freq = '15m'\n",
    "v = np.array(df[freq]['CLOSE'])\n",
    "v_all = np.matrix([df[freq]['OPEN'], df[freq]['HIGH'], df[freq]['LOW'], df[freq]['CLOSE'], df[freq]['VOLUME']]).T\n",
    "\n",
    "def split_train_test(data, test_split=0.1):\n",
    "    index = int(len(data) * 0.1)\n",
    "    return data[:-index], data[-index:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 : SELL, profit=0.0\n",
      "15 : BUY, profit=-0.0026005629258887904\n",
      "20 : SELL, profit=-0.005480102862414615\n",
      "21 : BUY, profit=-0.007291248737080556\n",
      "23 : SELL, profit=-0.010193229798854456\n",
      "35 : BUY, profit=-0.00679849442125971\n",
      "36 : SELL, profit=-0.012168854485815332\n",
      "42 : BUY, profit=-0.015518903209994654\n",
      "43 : SELL, profit=-0.017764816025081166\n",
      "59 : BUY, profit=0.12902495392539015\n",
      "61 : SELL, profit=0.12921563369074188\n",
      "62 : BUY, profit=0.12542201788172178\n",
      "67 : SELL, profit=0.12652802366870156\n",
      "68 : BUY, profit=0.12232115361177387\n",
      "69 : SELL, profit=0.11635057312720594\n",
      "79 : BUY, profit=0.12379505725840391\n",
      "80 : SELL, profit=0.11730466413429486\n",
      "81 : BUY, profit=0.11190723383298262\n",
      "84 : SELL, profit=0.11327793308288316\n",
      "85 : BUY, profit=0.11078457561821374\n",
      "92 : SELL, profit=0.1119799110822927\n",
      "93 : BUY, profit=0.10589854049618429\n",
      "97 : SELL, profit=0.10443155717774379\n",
      "98 : BUY, profit=0.10230972619519119\n",
      "100 : SELL, profit=0.09413916472974297\n",
      "118 : BUY, profit=0.2824048366903209\n",
      "120 : SELL, profit=0.2624592251444073\n",
      "125 : BUY, profit=0.27733929592101464\n",
      "130 : SELL, profit=0.2687449935958925\n",
      "131 : BUY, profit=0.25278952777077535\n",
      "132 : SELL, profit=0.23677917827942932\n",
      "134 : BUY, profit=0.22807476880884225\n",
      "140 : SELL, profit=0.22627385650458287\n",
      "158 : BUY, profit=0.261424051146354\n",
      "162 : SELL, profit=0.2525981065552655\n",
      "163 : BUY, profit=0.24938342073365688\n",
      "164 : SELL, profit=0.2404889761061568\n",
      "177 : BUY, profit=0.36959880779485366\n",
      "179 : SELL, profit=0.356720905046598\n",
      "181 : BUY, profit=0.30648388473057087\n",
      "188 : SELL, profit=0.31542293664930676\n",
      "198 : BUY, profit=0.3530453382985079\n",
      "199 : SELL, profit=0.31660458557189364\n",
      "202 : BUY, profit=0.2999422623706806\n",
      "220 : SELL, profit=0.4184477943662266\n",
      "222 : BUY, profit=0.41132263295650456\n",
      "228 : SELL, profit=0.4199577902021712\n",
      "230 : BUY, profit=0.4175698646189183\n",
      "231 : SELL, profit=0.40939725171247177\n",
      "232 : BUY, profit=0.3935540817575286\n",
      "235 : SELL, profit=0.372567454334149\n",
      "248 : BUY, profit=0.38455994435996455\n",
      "257 : SELL, profit=0.38926434580222097\n",
      "263 : BUY, profit=0.39426893423084425\n",
      "264 : SELL, profit=0.3897786766385955\n",
      "265 : BUY, profit=0.3757041720150816\n",
      "266 : SELL, profit=0.3657575405751873\n",
      "282 : BUY, profit=0.4153183740952411\n",
      "288 : SELL, profit=0.406499194171423\n",
      "306 : BUY, profit=0.4331778366358379\n",
      "308 : SELL, profit=0.420046235151396\n",
      "325 : BUY, profit=0.548947973859352\n",
      "331 : SELL, profit=0.5611154781536872\n",
      "336 : BUY, profit=0.5579568953324034\n",
      "337 : SELL, profit=0.5422685700611262\n",
      "338 : BUY, profit=0.5062051287218318\n",
      "344 : SELL, profit=0.4865781564223649\n",
      "345 : BUY, profit=0.47829205138387426\n",
      "350 : SELL, profit=0.5063441043900804\n",
      "351 : BUY, profit=0.49439728875541045\n",
      "352 : SELL, profit=0.48564193335071487\n",
      "374 : BUY, profit=0.5280061403994614\n",
      "375 : SELL, profit=0.5199144538155354\n",
      "378 : BUY, profit=0.5128260837213819\n",
      "386 : SELL, profit=0.5270761970566894\n",
      "387 : BUY, profit=0.5263507174914608\n",
      "388 : SELL, profit=0.518114846270538\n",
      "392 : BUY, profit=0.5159588341137467\n",
      "394 : SELL, profit=0.5148444615652363\n",
      "395 : BUY, profit=0.51334881219115\n",
      "396 : SELL, profit=0.5109365582527365\n",
      "413 : BUY, profit=0.563523724069161\n",
      "414 : SELL, profit=0.5601510658884785\n",
      "421 : BUY, profit=0.5666115504109837\n",
      "430 : SELL, profit=0.5752218407039328\n",
      "431 : BUY, profit=0.5725980305156696\n",
      "432 : SELL, profit=0.5683681967815144\n",
      "433 : BUY, profit=0.5631068801677798\n",
      "434 : SELL, profit=0.5560963466019464\n",
      "435 : BUY, profit=0.551747209852152\n",
      "436 : SELL, profit=0.5478831375035633\n",
      "438 : BUY, profit=0.5436724900720035\n",
      "451 : SELL, profit=0.6068239829752682\n",
      "453 : BUY, profit=0.6003774408871313\n",
      "456 : SELL, profit=0.6049115258903444\n",
      "457 : BUY, profit=0.6019334296358341\n",
      "469 : SELL, profit=0.6697308581056212\n",
      "475 : BUY, profit=0.6169382911259393\n",
      "481 : SELL, profit=0.5936492427490949\n",
      "482 : BUY, profit=0.5506418860241296\n",
      "486 : SELL, profit=0.5334636792451648\n",
      "487 : BUY, profit=0.5256710371046965\n",
      "488 : SELL, profit=0.519720089501575\n",
      "489 : BUY, profit=0.5138046053371454\n",
      "490 : SELL, profit=0.5101166253869132\n",
      "500 : BUY, profit=0.5390979608081615\n",
      "501 : SELL, profit=0.522644115628597\n",
      "503 : BUY, profit=0.5190443834505374\n",
      "514 : SELL, profit=0.5478725691435267\n",
      "516 : BUY, profit=0.5442868334576615\n",
      "517 : SELL, profit=0.5388664302375037\n",
      "519 : BUY, profit=0.49062426807534154\n",
      "524 : SELL, profit=0.480963727534801\n",
      "526 : BUY, profit=0.4690237059198025\n",
      "527 : SELL, profit=0.43880369457300694\n",
      "541 : BUY, profit=0.51430902116626\n",
      "547 : SELL, profit=0.5081439051486809\n",
      "552 : BUY, profit=0.5048951420300603\n",
      "556 : SELL, profit=0.5073017220950355\n",
      "563 : BUY, profit=0.5111245320886442\n",
      "564 : SELL, profit=0.506934098003884\n",
      "575 : BUY, profit=0.47945563961345056\n",
      "584 : SELL, profit=0.4767758446107285\n",
      "585 : BUY, profit=0.47068624043499996\n",
      "587 : SELL, profit=0.461016304464709\n",
      "590 : BUY, profit=0.4452103176654155\n",
      "591 : SELL, profit=0.40509225500854096\n",
      "595 : BUY, profit=0.3900796033616805\n",
      "597 : SELL, profit=0.3912410269283241\n",
      "600 : BUY, profit=0.38938407190658036\n",
      "604 : SELL, profit=0.38077930849596503\n",
      "619 : BUY, profit=0.40070264827880187\n",
      "621 : SELL, profit=0.3993768717088451\n",
      "625 : BUY, profit=0.3975847307238277\n",
      "638 : SELL, profit=0.41355263355213423\n",
      "645 : BUY, profit=0.41550330025095034\n",
      "646 : SELL, profit=0.4120600962387014\n",
      "653 : BUY, profit=0.4176390494976325\n",
      "657 : SELL, profit=0.4148726867172554\n"
     ]
    }
   ],
   "source": [
    "# heyhey logic\n",
    "\n",
    "# EMA\n",
    "_length = 7\n",
    "_, ema = split_train_test(talib.EMA(v, timeperiod=_length))\n",
    "_, test = split_train_test(v)\n",
    "\n",
    "# simulation\n",
    "profit = 0.0  # 利益\n",
    "position = 0  # -1 : 売りポジ, 0 : ポジなし, 1 : 買いポジ\n",
    "p_price = 0.0  # ポジションの額\n",
    "for i in range(2, len(test)):\n",
    "    if ema[i-2] >= ema[i-1] and ema[i-1] < ema[i]:  # buy\n",
    "        if position < 0:  # 売りポジ持ち\n",
    "            profit += (p_price - test[i]) / test[i]\n",
    "        print ('{0} : BUY, profit={1}'.format(i, profit))\n",
    "        p_price = test[i]\n",
    "        position = +1\n",
    "    elif ema[i-2] <= ema[i-1] and ema[i-1] > ema[i]:  # sell\n",
    "        if position > 0:  # 買いポジ持ち\n",
    "            profit += (test[i] - p_price) / p_price\n",
    "        print ('{0} : SELL, profit={1}'.format(i, profit))\n",
    "        p_price = test[i]\n",
    "        position = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 35584 samples, validate on 11862 samples\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34432/35584 [============================>.] - ETA: 1:35:10 - loss: 1.3863 - acc: 0.15 - ETA: 13:39 - loss: 1.3815 - acc: 0.3795 - ETA: 7:23 - loss: 1.3761 - acc: 0.3894 - ETA: 5:04 - loss: 1.3691 - acc: 0.399 - ETA: 3:52 - loss: 1.3607 - acc: 0.395 - ETA: 3:08 - loss: 1.3493 - acc: 0.394 - ETA: 2:43 - loss: 1.3352 - acc: 0.401 - ETA: 2:20 - loss: 1.3189 - acc: 0.401 - ETA: 2:03 - loss: 1.3071 - acc: 0.399 - ETA: 1:50 - loss: 1.2879 - acc: 0.403 - ETA: 1:41 - loss: 1.2793 - acc: 0.406 - ETA: 1:32 - loss: 1.2703 - acc: 0.403 - ETA: 1:24 - loss: 1.2588 - acc: 0.401 - ETA: 1:18 - loss: 1.2501 - acc: 0.400 - ETA: 1:13 - loss: 1.2404 - acc: 0.398 - ETA: 1:09 - loss: 1.2332 - acc: 0.402 - ETA: 1:05 - loss: 1.2288 - acc: 0.404 - ETA: 1:01 - loss: 1.2272 - acc: 0.405 - ETA: 58s - loss: 1.2225 - acc: 0.404 - ETA: 55s - loss: 1.2185 - acc: 0.40 - ETA: 52s - loss: 1.2161 - acc: 0.40 - ETA: 50s - loss: 1.2130 - acc: 0.40 - ETA: 48s - loss: 1.2103 - acc: 0.40 - ETA: 46s - loss: 1.2098 - acc: 0.41 - ETA: 44s - loss: 1.2061 - acc: 0.41 - ETA: 42s - loss: 1.1987 - acc: 0.41 - ETA: 41s - loss: 1.1972 - acc: 0.41 - ETA: 39s - loss: 1.2003 - acc: 0.41 - ETA: 38s - loss: 1.1986 - acc: 0.41 - ETA: 37s - loss: 1.1984 - acc: 0.42 - ETA: 36s - loss: 1.1977 - acc: 0.41 - ETA: 35s - loss: 1.1964 - acc: 0.41 - ETA: 34s - loss: 1.1971 - acc: 0.41 - ETA: 33s - loss: 1.1952 - acc: 0.41 - ETA: 32s - loss: 1.1943 - acc: 0.41 - ETA: 31s - loss: 1.1924 - acc: 0.41 - ETA: 30s - loss: 1.1906 - acc: 0.41 - ETA: 29s - loss: 1.1885 - acc: 0.41 - ETA: 29s - loss: 1.1888 - acc: 0.41 - ETA: 28s - loss: 1.1899 - acc: 0.41 - ETA: 27s - loss: 1.1882 - acc: 0.41 - ETA: 27s - loss: 1.1859 - acc: 0.41 - ETA: 26s - loss: 1.1844 - acc: 0.41 - ETA: 26s - loss: 1.1834 - acc: 0.41 - ETA: 25s - loss: 1.1848 - acc: 0.41 - ETA: 25s - loss: 1.1846 - acc: 0.41 - ETA: 24s - loss: 1.1837 - acc: 0.41 - ETA: 24s - loss: 1.1821 - acc: 0.41 - ETA: 23s - loss: 1.1829 - acc: 0.41 - ETA: 23s - loss: 1.1824 - acc: 0.41 - ETA: 22s - loss: 1.1816 - acc: 0.41 - ETA: 22s - loss: 1.1820 - acc: 0.41 - ETA: 22s - loss: 1.1809 - acc: 0.41 - ETA: 21s - loss: 1.1804 - acc: 0.41 - ETA: 21s - loss: 1.1794 - acc: 0.41 - ETA: 20s - loss: 1.1794 - acc: 0.41 - ETA: 20s - loss: 1.1786 - acc: 0.41 - ETA: 20s - loss: 1.1788 - acc: 0.41 - ETA: 20s - loss: 1.1790 - acc: 0.41 - ETA: 19s - loss: 1.1783 - acc: 0.41 - ETA: 19s - loss: 1.1780 - acc: 0.41 - ETA: 19s - loss: 1.1771 - acc: 0.41 - ETA: 18s - loss: 1.1770 - acc: 0.41 - ETA: 18s - loss: 1.1762 - acc: 0.41 - ETA: 18s - loss: 1.1752 - acc: 0.41 - ETA: 18s - loss: 1.1749 - acc: 0.42 - ETA: 18s - loss: 1.1743 - acc: 0.42 - ETA: 17s - loss: 1.1727 - acc: 0.42 - ETA: 17s - loss: 1.1735 - acc: 0.42 - ETA: 17s - loss: 1.1728 - acc: 0.42 - ETA: 17s - loss: 1.1728 - acc: 0.42 - ETA: 17s - loss: 1.1727 - acc: 0.42 - ETA: 16s - loss: 1.1729 - acc: 0.42 - ETA: 16s - loss: 1.1720 - acc: 0.42 - ETA: 16s - loss: 1.1728 - acc: 0.42 - ETA: 16s - loss: 1.1727 - acc: 0.42 - ETA: 16s - loss: 1.1729 - acc: 0.42 - ETA: 16s - loss: 1.1730 - acc: 0.42 - ETA: 15s - loss: 1.1726 - acc: 0.42 - ETA: 15s - loss: 1.1721 - acc: 0.42 - ETA: 15s - loss: 1.1722 - acc: 0.42 - ETA: 15s - loss: 1.1708 - acc: 0.42 - ETA: 15s - loss: 1.1710 - acc: 0.42 - ETA: 14s - loss: 1.1703 - acc: 0.42 - ETA: 14s - loss: 1.1693 - acc: 0.42 - ETA: 14s - loss: 1.1690 - acc: 0.42 - ETA: 14s - loss: 1.1683 - acc: 0.42 - ETA: 14s - loss: 1.1674 - acc: 0.42 - ETA: 14s - loss: 1.1661 - acc: 0.42 - ETA: 13s - loss: 1.1660 - acc: 0.42 - ETA: 13s - loss: 1.1654 - acc: 0.42 - ETA: 13s - loss: 1.1644 - acc: 0.42 - ETA: 13s - loss: 1.1636 - acc: 0.42 - ETA: 13s - loss: 1.1637 - acc: 0.42 - ETA: 13s - loss: 1.1632 - acc: 0.42 - ETA: 12s - loss: 1.1624 - acc: 0.42 - ETA: 12s - loss: 1.1616 - acc: 0.42 - ETA: 12s - loss: 1.1604 - acc: 0.42 - ETA: 12s - loss: 1.1614 - acc: 0.42 - ETA: 12s - loss: 1.1600 - acc: 0.42 - ETA: 11s - loss: 1.1606 - acc: 0.42 - ETA: 11s - loss: 1.1597 - acc: 0.42 - ETA: 11s - loss: 1.1602 - acc: 0.42 - ETA: 11s - loss: 1.1599 - acc: 0.42 - ETA: 11s - loss: 1.1586 - acc: 0.42 - ETA: 10s - loss: 1.1575 - acc: 0.42 - ETA: 10s - loss: 1.1574 - acc: 0.42 - ETA: 10s - loss: 1.1559 - acc: 0.42 - ETA: 10s - loss: 1.1548 - acc: 0.42 - ETA: 10s - loss: 1.1541 - acc: 0.42 - ETA: 10s - loss: 1.1545 - acc: 0.42 - ETA: 10s - loss: 1.1535 - acc: 0.42 - ETA: 9s - loss: 1.1537 - acc: 0.4272 - ETA: 9s - loss: 1.1534 - acc: 0.426 - ETA: 9s - loss: 1.1529 - acc: 0.427 - ETA: 9s - loss: 1.1526 - acc: 0.427 - ETA: 9s - loss: 1.1522 - acc: 0.427 - ETA: 9s - loss: 1.1515 - acc: 0.428 - ETA: 8s - loss: 1.1511 - acc: 0.428 - ETA: 8s - loss: 1.1500 - acc: 0.428 - ETA: 8s - loss: 1.1497 - acc: 0.428 - ETA: 8s - loss: 1.1489 - acc: 0.428 - ETA: 8s - loss: 1.1479 - acc: 0.429 - ETA: 8s - loss: 1.1475 - acc: 0.429 - ETA: 8s - loss: 1.1475 - acc: 0.429 - ETA: 8s - loss: 1.1472 - acc: 0.429 - ETA: 8s - loss: 1.1470 - acc: 0.429 - ETA: 7s - loss: 1.1466 - acc: 0.430 - ETA: 7s - loss: 1.1466 - acc: 0.430 - ETA: 7s - loss: 1.1464 - acc: 0.430 - ETA: 7s - loss: 1.1457 - acc: 0.430 - ETA: 7s - loss: 1.1453 - acc: 0.430 - ETA: 7s - loss: 1.1451 - acc: 0.430 - ETA: 7s - loss: 1.1447 - acc: 0.430 - ETA: 7s - loss: 1.1440 - acc: 0.430 - ETA: 6s - loss: 1.1434 - acc: 0.430 - ETA: 6s - loss: 1.1435 - acc: 0.430 - ETA: 6s - loss: 1.1430 - acc: 0.430 - ETA: 6s - loss: 1.1422 - acc: 0.431 - ETA: 6s - loss: 1.1423 - acc: 0.431 - ETA: 6s - loss: 1.1420 - acc: 0.431 - ETA: 6s - loss: 1.1418 - acc: 0.432 - ETA: 6s - loss: 1.1422 - acc: 0.432 - ETA: 6s - loss: 1.1418 - acc: 0.432 - ETA: 6s - loss: 1.1414 - acc: 0.432 - ETA: 5s - loss: 1.1412 - acc: 0.432 - ETA: 5s - loss: 1.1407 - acc: 0.432 - ETA: 5s - loss: 1.1394 - acc: 0.432 - ETA: 5s - loss: 1.1398 - acc: 0.432 - ETA: 5s - loss: 1.1396 - acc: 0.432 - ETA: 5s - loss: 1.1394 - acc: 0.432 - ETA: 5s - loss: 1.1391 - acc: 0.432 - ETA: 5s - loss: 1.1387 - acc: 0.432 - ETA: 5s - loss: 1.1386 - acc: 0.431 - ETA: 5s - loss: 1.1388 - acc: 0.432 - ETA: 5s - loss: 1.1383 - acc: 0.432 - ETA: 5s - loss: 1.1382 - acc: 0.432 - ETA: 4s - loss: 1.1378 - acc: 0.432 - ETA: 4s - loss: 1.1377 - acc: 0.432 - ETA: 4s - loss: 1.1371 - acc: 0.432 - ETA: 4s - loss: 1.1370 - acc: 0.432 - ETA: 4s - loss: 1.1369 - acc: 0.432 - ETA: 4s - loss: 1.1368 - acc: 0.432 - ETA: 4s - loss: 1.1364 - acc: 0.433 - ETA: 4s - loss: 1.1362 - acc: 0.433 - ETA: 4s - loss: 1.1355 - acc: 0.433 - ETA: 4s - loss: 1.1353 - acc: 0.433 - ETA: 4s - loss: 1.1351 - acc: 0.433 - ETA: 4s - loss: 1.1343 - acc: 0.434 - ETA: 3s - loss: 1.1340 - acc: 0.434 - ETA: 3s - loss: 1.1331 - acc: 0.434 - ETA: 3s - loss: 1.1330 - acc: 0.434 - ETA: 3s - loss: 1.1324 - acc: 0.435 - ETA: 3s - loss: 1.1322 - acc: 0.435 - ETA: 3s - loss: 1.1325 - acc: 0.435 - ETA: 3s - loss: 1.1328 - acc: 0.435 - ETA: 3s - loss: 1.1326 - acc: 0.435 - ETA: 3s - loss: 1.1328 - acc: 0.435 - ETA: 3s - loss: 1.1328 - acc: 0.435 - ETA: 3s - loss: 1.1322 - acc: 0.435 - ETA: 3s - loss: 1.1316 - acc: 0.435 - ETA: 3s - loss: 1.1318 - acc: 0.435 - ETA: 3s - loss: 1.1316 - acc: 0.435 - ETA: 2s - loss: 1.1311 - acc: 0.435 - ETA: 2s - loss: 1.1310 - acc: 0.435 - ETA: 2s - loss: 1.1308 - acc: 0.435 - ETA: 2s - loss: 1.1307 - acc: 0.435 - ETA: 2s - loss: 1.1308 - acc: 0.435 - ETA: 2s - loss: 1.1311 - acc: 0.435 - ETA: 2s - loss: 1.1310 - acc: 0.435 - ETA: 2s - loss: 1.1306 - acc: 0.435 - ETA: 2s - loss: 1.1308 - acc: 0.435 - ETA: 2s - loss: 1.1305 - acc: 0.435 - ETA: 2s - loss: 1.1302 - acc: 0.435 - ETA: 1s - loss: 1.1303 - acc: 0.435 - ETA: 1s - loss: 1.1304 - acc: 0.435 - ETA: 1s - loss: 1.1301 - acc: 0.435 - ETA: 1s - loss: 1.1295 - acc: 0.436 - ETA: 1s - loss: 1.1294 - acc: 0.435 - ETA: 1s - loss: 1.1292 - acc: 0.435 - ETA: 1s - loss: 1.1290 - acc: 0.435 - ETA: 1s - loss: 1.1289 - acc: 0.435 - ETA: 1s - loss: 1.1283 - acc: 0.436 - ETA: 1s - loss: 1.1279 - acc: 0.436 - ETA: 1s - loss: 1.1272 - acc: 0.436 - ETA: 1s - loss: 1.1272 - acc: 0.436 - ETA: 0s - loss: 1.1270 - acc: 0.436 - ETA: 0s - loss: 1.1269 - acc: 0.436 - ETA: 0s - loss: 1.1268 - acc: 0.436 - ETA: 0s - loss: 1.1265 - acc: 0.436 - ETA: 0s - loss: 1.1264 - acc: 0.436 - ETA: 0s - loss: 1.1269 - acc: 0.4361\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35584/35584 [==============================] - ETA: 0s - loss: 1.1268 - acc: 0.436 - ETA: 0s - loss: 1.1267 - acc: 0.436 - ETA: 0s - loss: 1.1265 - acc: 0.436 - ETA: 0s - loss: 1.1266 - acc: 0.436 - ETA: 0s - loss: 1.1263 - acc: 0.436 - ETA: 0s - loss: 1.1262 - acc: 0.436 - 18s 520us/step - loss: 1.1257 - acc: 0.4368 - val_loss: 1.0868 - val_acc: 0.4468\n",
      "Epoch 2/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34816/35584 [============================>.] - ETA: 18s - loss: 1.1549 - acc: 0.28 - ETA: 12s - loss: 1.0835 - acc: 0.40 - ETA: 11s - loss: 1.0910 - acc: 0.42 - ETA: 11s - loss: 1.0878 - acc: 0.42 - ETA: 11s - loss: 1.0935 - acc: 0.41 - ETA: 10s - loss: 1.1007 - acc: 0.42 - ETA: 10s - loss: 1.1107 - acc: 0.42 - ETA: 10s - loss: 1.1123 - acc: 0.42 - ETA: 10s - loss: 1.1064 - acc: 0.42 - ETA: 11s - loss: 1.1017 - acc: 0.43 - ETA: 11s - loss: 1.1017 - acc: 0.43 - ETA: 11s - loss: 1.1011 - acc: 0.43 - ETA: 11s - loss: 1.0996 - acc: 0.43 - ETA: 11s - loss: 1.0999 - acc: 0.43 - ETA: 11s - loss: 1.0975 - acc: 0.43 - ETA: 11s - loss: 1.0950 - acc: 0.42 - ETA: 11s - loss: 1.0986 - acc: 0.43 - ETA: 11s - loss: 1.0943 - acc: 0.42 - ETA: 11s - loss: 1.0949 - acc: 0.43 - ETA: 11s - loss: 1.0944 - acc: 0.43 - ETA: 11s - loss: 1.0934 - acc: 0.43 - ETA: 11s - loss: 1.0918 - acc: 0.43 - ETA: 10s - loss: 1.0915 - acc: 0.43 - ETA: 10s - loss: 1.0887 - acc: 0.43 - ETA: 10s - loss: 1.0877 - acc: 0.43 - ETA: 10s - loss: 1.0871 - acc: 0.43 - ETA: 10s - loss: 1.0865 - acc: 0.43 - ETA: 10s - loss: 1.0863 - acc: 0.43 - ETA: 10s - loss: 1.0876 - acc: 0.43 - ETA: 10s - loss: 1.0910 - acc: 0.43 - ETA: 10s - loss: 1.0916 - acc: 0.43 - ETA: 10s - loss: 1.0906 - acc: 0.43 - ETA: 10s - loss: 1.0906 - acc: 0.43 - ETA: 10s - loss: 1.0910 - acc: 0.44 - ETA: 10s - loss: 1.0887 - acc: 0.44 - ETA: 10s - loss: 1.0889 - acc: 0.44 - ETA: 9s - loss: 1.0896 - acc: 0.4421 - ETA: 9s - loss: 1.0901 - acc: 0.440 - ETA: 9s - loss: 1.0903 - acc: 0.442 - ETA: 9s - loss: 1.0903 - acc: 0.443 - ETA: 9s - loss: 1.0913 - acc: 0.442 - ETA: 9s - loss: 1.0930 - acc: 0.441 - ETA: 9s - loss: 1.0930 - acc: 0.440 - ETA: 9s - loss: 1.0935 - acc: 0.440 - ETA: 9s - loss: 1.0952 - acc: 0.439 - ETA: 9s - loss: 1.0951 - acc: 0.440 - ETA: 9s - loss: 1.0948 - acc: 0.440 - ETA: 9s - loss: 1.0955 - acc: 0.440 - ETA: 9s - loss: 1.0934 - acc: 0.440 - ETA: 9s - loss: 1.0951 - acc: 0.440 - ETA: 9s - loss: 1.0943 - acc: 0.441 - ETA: 9s - loss: 1.0937 - acc: 0.442 - ETA: 8s - loss: 1.0934 - acc: 0.441 - ETA: 8s - loss: 1.0914 - acc: 0.443 - ETA: 8s - loss: 1.0907 - acc: 0.443 - ETA: 8s - loss: 1.0913 - acc: 0.441 - ETA: 8s - loss: 1.0918 - acc: 0.441 - ETA: 8s - loss: 1.0914 - acc: 0.441 - ETA: 8s - loss: 1.0915 - acc: 0.440 - ETA: 8s - loss: 1.0928 - acc: 0.439 - ETA: 8s - loss: 1.0941 - acc: 0.438 - ETA: 8s - loss: 1.0945 - acc: 0.439 - ETA: 8s - loss: 1.0930 - acc: 0.439 - ETA: 8s - loss: 1.0917 - acc: 0.439 - ETA: 8s - loss: 1.0927 - acc: 0.438 - ETA: 8s - loss: 1.0917 - acc: 0.438 - ETA: 8s - loss: 1.0910 - acc: 0.438 - ETA: 7s - loss: 1.0907 - acc: 0.437 - ETA: 7s - loss: 1.0912 - acc: 0.437 - ETA: 7s - loss: 1.0910 - acc: 0.438 - ETA: 7s - loss: 1.0911 - acc: 0.438 - ETA: 7s - loss: 1.0922 - acc: 0.438 - ETA: 7s - loss: 1.0921 - acc: 0.438 - ETA: 7s - loss: 1.0916 - acc: 0.438 - ETA: 7s - loss: 1.0919 - acc: 0.439 - ETA: 7s - loss: 1.0930 - acc: 0.438 - ETA: 7s - loss: 1.0924 - acc: 0.439 - ETA: 7s - loss: 1.0917 - acc: 0.440 - ETA: 7s - loss: 1.0908 - acc: 0.440 - ETA: 7s - loss: 1.0904 - acc: 0.440 - ETA: 7s - loss: 1.0894 - acc: 0.441 - ETA: 7s - loss: 1.0891 - acc: 0.441 - ETA: 7s - loss: 1.0888 - acc: 0.441 - ETA: 7s - loss: 1.0883 - acc: 0.441 - ETA: 7s - loss: 1.0876 - acc: 0.441 - ETA: 7s - loss: 1.0878 - acc: 0.441 - ETA: 7s - loss: 1.0877 - acc: 0.442 - ETA: 7s - loss: 1.0870 - acc: 0.442 - ETA: 7s - loss: 1.0870 - acc: 0.442 - ETA: 6s - loss: 1.0870 - acc: 0.442 - ETA: 6s - loss: 1.0867 - acc: 0.442 - ETA: 6s - loss: 1.0873 - acc: 0.442 - ETA: 6s - loss: 1.0877 - acc: 0.442 - ETA: 6s - loss: 1.0876 - acc: 0.443 - ETA: 6s - loss: 1.0874 - acc: 0.443 - ETA: 6s - loss: 1.0879 - acc: 0.443 - ETA: 6s - loss: 1.0882 - acc: 0.443 - ETA: 6s - loss: 1.0886 - acc: 0.443 - ETA: 6s - loss: 1.0881 - acc: 0.443 - ETA: 6s - loss: 1.0886 - acc: 0.443 - ETA: 6s - loss: 1.0882 - acc: 0.444 - ETA: 6s - loss: 1.0881 - acc: 0.444 - ETA: 6s - loss: 1.0889 - acc: 0.444 - ETA: 6s - loss: 1.0891 - acc: 0.444 - ETA: 6s - loss: 1.0889 - acc: 0.444 - ETA: 6s - loss: 1.0880 - acc: 0.444 - ETA: 5s - loss: 1.0882 - acc: 0.444 - ETA: 5s - loss: 1.0874 - acc: 0.444 - ETA: 5s - loss: 1.0868 - acc: 0.444 - ETA: 5s - loss: 1.0873 - acc: 0.445 - ETA: 5s - loss: 1.0869 - acc: 0.445 - ETA: 5s - loss: 1.0871 - acc: 0.445 - ETA: 5s - loss: 1.0871 - acc: 0.446 - ETA: 5s - loss: 1.0875 - acc: 0.446 - ETA: 5s - loss: 1.0877 - acc: 0.446 - ETA: 5s - loss: 1.0876 - acc: 0.446 - ETA: 5s - loss: 1.0876 - acc: 0.445 - ETA: 5s - loss: 1.0871 - acc: 0.445 - ETA: 5s - loss: 1.0874 - acc: 0.445 - ETA: 5s - loss: 1.0869 - acc: 0.445 - ETA: 5s - loss: 1.0868 - acc: 0.446 - ETA: 5s - loss: 1.0873 - acc: 0.445 - ETA: 4s - loss: 1.0872 - acc: 0.445 - ETA: 4s - loss: 1.0867 - acc: 0.445 - ETA: 4s - loss: 1.0865 - acc: 0.445 - ETA: 4s - loss: 1.0865 - acc: 0.445 - ETA: 4s - loss: 1.0862 - acc: 0.445 - ETA: 4s - loss: 1.0861 - acc: 0.444 - ETA: 4s - loss: 1.0861 - acc: 0.444 - ETA: 4s - loss: 1.0859 - acc: 0.444 - ETA: 4s - loss: 1.0857 - acc: 0.445 - ETA: 4s - loss: 1.0854 - acc: 0.444 - ETA: 4s - loss: 1.0854 - acc: 0.444 - ETA: 4s - loss: 1.0851 - acc: 0.445 - ETA: 4s - loss: 1.0854 - acc: 0.445 - ETA: 4s - loss: 1.0856 - acc: 0.444 - ETA: 4s - loss: 1.0854 - acc: 0.444 - ETA: 4s - loss: 1.0855 - acc: 0.445 - ETA: 4s - loss: 1.0856 - acc: 0.445 - ETA: 4s - loss: 1.0850 - acc: 0.445 - ETA: 4s - loss: 1.0854 - acc: 0.445 - ETA: 4s - loss: 1.0857 - acc: 0.445 - ETA: 3s - loss: 1.0860 - acc: 0.445 - ETA: 3s - loss: 1.0860 - acc: 0.444 - ETA: 3s - loss: 1.0863 - acc: 0.444 - ETA: 3s - loss: 1.0863 - acc: 0.445 - ETA: 3s - loss: 1.0860 - acc: 0.445 - ETA: 3s - loss: 1.0864 - acc: 0.445 - ETA: 3s - loss: 1.0864 - acc: 0.445 - ETA: 3s - loss: 1.0865 - acc: 0.445 - ETA: 3s - loss: 1.0867 - acc: 0.445 - ETA: 3s - loss: 1.0867 - acc: 0.445 - ETA: 3s - loss: 1.0867 - acc: 0.445 - ETA: 3s - loss: 1.0862 - acc: 0.445 - ETA: 3s - loss: 1.0858 - acc: 0.445 - ETA: 3s - loss: 1.0856 - acc: 0.445 - ETA: 3s - loss: 1.0860 - acc: 0.445 - ETA: 3s - loss: 1.0856 - acc: 0.445 - ETA: 3s - loss: 1.0858 - acc: 0.445 - ETA: 3s - loss: 1.0853 - acc: 0.445 - ETA: 3s - loss: 1.0853 - acc: 0.445 - ETA: 3s - loss: 1.0854 - acc: 0.445 - ETA: 3s - loss: 1.0859 - acc: 0.445 - ETA: 3s - loss: 1.0862 - acc: 0.445 - ETA: 2s - loss: 1.0858 - acc: 0.445 - ETA: 2s - loss: 1.0866 - acc: 0.445 - ETA: 2s - loss: 1.0868 - acc: 0.444 - ETA: 2s - loss: 1.0866 - acc: 0.444 - ETA: 2s - loss: 1.0863 - acc: 0.445 - ETA: 2s - loss: 1.0861 - acc: 0.445 - ETA: 2s - loss: 1.0864 - acc: 0.445 - ETA: 2s - loss: 1.0865 - acc: 0.445 - ETA: 2s - loss: 1.0864 - acc: 0.445 - ETA: 2s - loss: 1.0864 - acc: 0.445 - ETA: 2s - loss: 1.0865 - acc: 0.445 - ETA: 2s - loss: 1.0863 - acc: 0.444 - ETA: 2s - loss: 1.0861 - acc: 0.445 - ETA: 2s - loss: 1.0861 - acc: 0.445 - ETA: 2s - loss: 1.0858 - acc: 0.445 - ETA: 2s - loss: 1.0855 - acc: 0.445 - ETA: 2s - loss: 1.0855 - acc: 0.445 - ETA: 1s - loss: 1.0856 - acc: 0.445 - ETA: 1s - loss: 1.0860 - acc: 0.445 - ETA: 1s - loss: 1.0864 - acc: 0.445 - ETA: 1s - loss: 1.0862 - acc: 0.445 - ETA: 1s - loss: 1.0864 - acc: 0.445 - ETA: 1s - loss: 1.0864 - acc: 0.445 - ETA: 1s - loss: 1.0863 - acc: 0.445 - ETA: 1s - loss: 1.0866 - acc: 0.445 - ETA: 1s - loss: 1.0869 - acc: 0.445 - ETA: 1s - loss: 1.0872 - acc: 0.444 - ETA: 1s - loss: 1.0875 - acc: 0.445 - ETA: 1s - loss: 1.0875 - acc: 0.445 - ETA: 1s - loss: 1.0874 - acc: 0.445 - ETA: 1s - loss: 1.0873 - acc: 0.445 - ETA: 1s - loss: 1.0875 - acc: 0.445 - ETA: 1s - loss: 1.0878 - acc: 0.445 - ETA: 1s - loss: 1.0881 - acc: 0.445 - ETA: 1s - loss: 1.0880 - acc: 0.445 - ETA: 0s - loss: 1.0879 - acc: 0.445 - ETA: 0s - loss: 1.0878 - acc: 0.445 - ETA: 0s - loss: 1.0877 - acc: 0.446 - ETA: 0s - loss: 1.0874 - acc: 0.446 - ETA: 0s - loss: 1.0875 - acc: 0.446 - ETA: 0s - loss: 1.0872 - acc: 0.446 - ETA: 0s - loss: 1.0872 - acc: 0.446 - ETA: 0s - loss: 1.0870 - acc: 0.446 - ETA: 0s - loss: 1.0870 - acc: 0.446 - ETA: 0s - loss: 1.0869 - acc: 0.446 - ETA: 0s - loss: 1.0867 - acc: 0.446 - ETA: 0s - loss: 1.0866 - acc: 0.446 - ETA: 0s - loss: 1.0865 - acc: 0.446 - ETA: 0s - loss: 1.0865 - acc: 0.446 - ETA: 0s - loss: 1.0863 - acc: 0.446 - ETA: 0s - loss: 1.0863 - acc: 0.4465"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35584/35584 [==============================] - ETA: 0s - loss: 1.0861 - acc: 0.446 - ETA: 0s - loss: 1.0861 - acc: 0.446 - ETA: 0s - loss: 1.0860 - acc: 0.446 - ETA: 0s - loss: 1.0860 - acc: 0.446 - 13s 361us/step - loss: 1.0859 - acc: 0.4466 - val_loss: 1.0681 - val_acc: 0.4606\n",
      "Epoch 3/100\n",
      "35584/35584 [==============================] - ETA: 14s - loss: 1.0264 - acc: 0.50 - ETA: 12s - loss: 1.0773 - acc: 0.45 - ETA: 12s - loss: 1.0800 - acc: 0.46 - ETA: 11s - loss: 1.0900 - acc: 0.45 - ETA: 11s - loss: 1.1056 - acc: 0.44 - ETA: 10s - loss: 1.1137 - acc: 0.44 - ETA: 10s - loss: 1.1082 - acc: 0.44 - ETA: 10s - loss: 1.1112 - acc: 0.44 - ETA: 10s - loss: 1.1068 - acc: 0.44 - ETA: 10s - loss: 1.1001 - acc: 0.44 - ETA: 10s - loss: 1.1009 - acc: 0.44 - ETA: 9s - loss: 1.0944 - acc: 0.4457 - ETA: 9s - loss: 1.0926 - acc: 0.441 - ETA: 9s - loss: 1.0934 - acc: 0.442 - ETA: 9s - loss: 1.0899 - acc: 0.445 - ETA: 9s - loss: 1.0894 - acc: 0.444 - ETA: 9s - loss: 1.0869 - acc: 0.443 - ETA: 9s - loss: 1.0859 - acc: 0.441 - ETA: 9s - loss: 1.0812 - acc: 0.443 - ETA: 9s - loss: 1.0815 - acc: 0.443 - ETA: 9s - loss: 1.0814 - acc: 0.446 - ETA: 9s - loss: 1.0808 - acc: 0.447 - ETA: 9s - loss: 1.0806 - acc: 0.450 - ETA: 9s - loss: 1.0823 - acc: 0.447 - ETA: 9s - loss: 1.0816 - acc: 0.447 - ETA: 9s - loss: 1.0842 - acc: 0.445 - ETA: 9s - loss: 1.0856 - acc: 0.445 - ETA: 9s - loss: 1.0867 - acc: 0.445 - ETA: 8s - loss: 1.0883 - acc: 0.444 - ETA: 8s - loss: 1.0894 - acc: 0.443 - ETA: 8s - loss: 1.0890 - acc: 0.445 - ETA: 8s - loss: 1.0883 - acc: 0.443 - ETA: 8s - loss: 1.0877 - acc: 0.444 - ETA: 8s - loss: 1.0888 - acc: 0.444 - ETA: 8s - loss: 1.0877 - acc: 0.444 - ETA: 8s - loss: 1.0907 - acc: 0.444 - ETA: 8s - loss: 1.0909 - acc: 0.446 - ETA: 8s - loss: 1.0916 - acc: 0.445 - ETA: 8s - loss: 1.0916 - acc: 0.445 - ETA: 8s - loss: 1.0904 - acc: 0.446 - ETA: 8s - loss: 1.0918 - acc: 0.445 - ETA: 8s - loss: 1.0914 - acc: 0.445 - ETA: 8s - loss: 1.0927 - acc: 0.445 - ETA: 8s - loss: 1.0926 - acc: 0.446 - ETA: 8s - loss: 1.0917 - acc: 0.445 - ETA: 8s - loss: 1.0905 - acc: 0.447 - ETA: 8s - loss: 1.0892 - acc: 0.449 - ETA: 7s - loss: 1.0893 - acc: 0.448 - ETA: 7s - loss: 1.0885 - acc: 0.448 - ETA: 7s - loss: 1.0871 - acc: 0.449 - ETA: 7s - loss: 1.0863 - acc: 0.449 - ETA: 7s - loss: 1.0862 - acc: 0.449 - ETA: 7s - loss: 1.0858 - acc: 0.450 - ETA: 7s - loss: 1.0862 - acc: 0.449 - ETA: 7s - loss: 1.0856 - acc: 0.449 - ETA: 7s - loss: 1.0851 - acc: 0.448 - ETA: 7s - loss: 1.0855 - acc: 0.449 - ETA: 7s - loss: 1.0861 - acc: 0.449 - ETA: 7s - loss: 1.0861 - acc: 0.450 - ETA: 7s - loss: 1.0863 - acc: 0.450 - ETA: 7s - loss: 1.0858 - acc: 0.449 - ETA: 7s - loss: 1.0861 - acc: 0.449 - ETA: 7s - loss: 1.0861 - acc: 0.449 - ETA: 7s - loss: 1.0862 - acc: 0.449 - ETA: 7s - loss: 1.0859 - acc: 0.449 - ETA: 7s - loss: 1.0850 - acc: 0.450 - ETA: 7s - loss: 1.0852 - acc: 0.451 - ETA: 7s - loss: 1.0853 - acc: 0.451 - ETA: 7s - loss: 1.0852 - acc: 0.450 - ETA: 7s - loss: 1.0842 - acc: 0.451 - ETA: 7s - loss: 1.0847 - acc: 0.451 - ETA: 7s - loss: 1.0858 - acc: 0.450 - ETA: 7s - loss: 1.0866 - acc: 0.450 - ETA: 7s - loss: 1.0869 - acc: 0.450 - ETA: 7s - loss: 1.0864 - acc: 0.450 - ETA: 6s - loss: 1.0870 - acc: 0.450 - ETA: 6s - loss: 1.0877 - acc: 0.450 - ETA: 6s - loss: 1.0882 - acc: 0.449 - ETA: 6s - loss: 1.0882 - acc: 0.448 - ETA: 6s - loss: 1.0881 - acc: 0.448 - ETA: 6s - loss: 1.0878 - acc: 0.448 - ETA: 6s - loss: 1.0884 - acc: 0.447 - ETA: 6s - loss: 1.0891 - acc: 0.447 - ETA: 6s - loss: 1.0895 - acc: 0.447 - ETA: 6s - loss: 1.0895 - acc: 0.447 - ETA: 6s - loss: 1.0894 - acc: 0.447 - ETA: 6s - loss: 1.0893 - acc: 0.447 - ETA: 6s - loss: 1.0888 - acc: 0.447 - ETA: 6s - loss: 1.0878 - acc: 0.447 - ETA: 6s - loss: 1.0879 - acc: 0.448 - ETA: 6s - loss: 1.0877 - acc: 0.448 - ETA: 6s - loss: 1.0878 - acc: 0.448 - ETA: 6s - loss: 1.0885 - acc: 0.448 - ETA: 5s - loss: 1.0887 - acc: 0.448 - ETA: 5s - loss: 1.0881 - acc: 0.448 - ETA: 5s - loss: 1.0876 - acc: 0.448 - ETA: 5s - loss: 1.0881 - acc: 0.448 - ETA: 5s - loss: 1.0883 - acc: 0.448 - ETA: 5s - loss: 1.0889 - acc: 0.448 - ETA: 5s - loss: 1.0889 - acc: 0.447 - ETA: 5s - loss: 1.0883 - acc: 0.447 - ETA: 5s - loss: 1.0891 - acc: 0.448 - ETA: 5s - loss: 1.0891 - acc: 0.448 - ETA: 5s - loss: 1.0892 - acc: 0.448 - ETA: 5s - loss: 1.0889 - acc: 0.448 - ETA: 5s - loss: 1.0885 - acc: 0.449 - ETA: 5s - loss: 1.0876 - acc: 0.449 - ETA: 5s - loss: 1.0878 - acc: 0.449 - ETA: 5s - loss: 1.0877 - acc: 0.450 - ETA: 5s - loss: 1.0875 - acc: 0.450 - ETA: 5s - loss: 1.0875 - acc: 0.449 - ETA: 5s - loss: 1.0874 - acc: 0.449 - ETA: 5s - loss: 1.0875 - acc: 0.449 - ETA: 5s - loss: 1.0878 - acc: 0.449 - ETA: 5s - loss: 1.0872 - acc: 0.449 - ETA: 5s - loss: 1.0872 - acc: 0.449 - ETA: 5s - loss: 1.0871 - acc: 0.449 - ETA: 5s - loss: 1.0866 - acc: 0.450 - ETA: 5s - loss: 1.0857 - acc: 0.450 - ETA: 5s - loss: 1.0853 - acc: 0.450 - ETA: 4s - loss: 1.0849 - acc: 0.451 - ETA: 4s - loss: 1.0853 - acc: 0.451 - ETA: 4s - loss: 1.0853 - acc: 0.451 - ETA: 4s - loss: 1.0855 - acc: 0.451 - ETA: 4s - loss: 1.0857 - acc: 0.451 - ETA: 4s - loss: 1.0856 - acc: 0.451 - ETA: 4s - loss: 1.0849 - acc: 0.451 - ETA: 4s - loss: 1.0849 - acc: 0.451 - ETA: 4s - loss: 1.0848 - acc: 0.451 - ETA: 4s - loss: 1.0847 - acc: 0.450 - ETA: 4s - loss: 1.0845 - acc: 0.450 - ETA: 4s - loss: 1.0847 - acc: 0.450 - ETA: 4s - loss: 1.0845 - acc: 0.450 - ETA: 4s - loss: 1.0845 - acc: 0.450 - ETA: 4s - loss: 1.0852 - acc: 0.449 - ETA: 4s - loss: 1.0856 - acc: 0.450 - ETA: 4s - loss: 1.0855 - acc: 0.450 - ETA: 3s - loss: 1.0853 - acc: 0.450 - ETA: 3s - loss: 1.0849 - acc: 0.450 - ETA: 3s - loss: 1.0857 - acc: 0.450 - ETA: 3s - loss: 1.0860 - acc: 0.450 - ETA: 3s - loss: 1.0864 - acc: 0.449 - ETA: 3s - loss: 1.0864 - acc: 0.450 - ETA: 3s - loss: 1.0862 - acc: 0.450 - ETA: 3s - loss: 1.0866 - acc: 0.450 - ETA: 3s - loss: 1.0863 - acc: 0.450 - ETA: 3s - loss: 1.0860 - acc: 0.451 - ETA: 3s - loss: 1.0855 - acc: 0.451 - ETA: 3s - loss: 1.0851 - acc: 0.451 - ETA: 3s - loss: 1.0857 - acc: 0.450 - ETA: 3s - loss: 1.0858 - acc: 0.450 - ETA: 3s - loss: 1.0856 - acc: 0.450 - ETA: 3s - loss: 1.0860 - acc: 0.450 - ETA: 3s - loss: 1.0857 - acc: 0.451 - ETA: 2s - loss: 1.0860 - acc: 0.451 - ETA: 2s - loss: 1.0856 - acc: 0.451 - ETA: 2s - loss: 1.0858 - acc: 0.451 - ETA: 2s - loss: 1.0858 - acc: 0.450 - ETA: 2s - loss: 1.0852 - acc: 0.450 - ETA: 2s - loss: 1.0856 - acc: 0.451 - ETA: 2s - loss: 1.0854 - acc: 0.451 - ETA: 2s - loss: 1.0850 - acc: 0.451 - ETA: 2s - loss: 1.0855 - acc: 0.451 - ETA: 2s - loss: 1.0855 - acc: 0.451 - ETA: 2s - loss: 1.0853 - acc: 0.452 - ETA: 2s - loss: 1.0849 - acc: 0.452 - ETA: 2s - loss: 1.0847 - acc: 0.452 - ETA: 2s - loss: 1.0852 - acc: 0.451 - ETA: 2s - loss: 1.0851 - acc: 0.451 - ETA: 2s - loss: 1.0852 - acc: 0.451 - ETA: 1s - loss: 1.0848 - acc: 0.451 - ETA: 1s - loss: 1.0846 - acc: 0.452 - ETA: 1s - loss: 1.0844 - acc: 0.452 - ETA: 1s - loss: 1.0841 - acc: 0.452 - ETA: 1s - loss: 1.0839 - acc: 0.452 - ETA: 1s - loss: 1.0843 - acc: 0.452 - ETA: 1s - loss: 1.0841 - acc: 0.452 - ETA: 1s - loss: 1.0841 - acc: 0.452 - ETA: 1s - loss: 1.0838 - acc: 0.452 - ETA: 1s - loss: 1.0838 - acc: 0.452 - ETA: 1s - loss: 1.0839 - acc: 0.452 - ETA: 1s - loss: 1.0843 - acc: 0.452 - ETA: 1s - loss: 1.0843 - acc: 0.452 - ETA: 1s - loss: 1.0844 - acc: 0.451 - ETA: 1s - loss: 1.0841 - acc: 0.451 - ETA: 1s - loss: 1.0842 - acc: 0.452 - ETA: 1s - loss: 1.0844 - acc: 0.451 - ETA: 0s - loss: 1.0842 - acc: 0.452 - ETA: 0s - loss: 1.0838 - acc: 0.452 - ETA: 0s - loss: 1.0838 - acc: 0.452 - ETA: 0s - loss: 1.0834 - acc: 0.452 - ETA: 0s - loss: 1.0832 - acc: 0.451 - ETA: 0s - loss: 1.0831 - acc: 0.452 - ETA: 0s - loss: 1.0831 - acc: 0.452 - ETA: 0s - loss: 1.0831 - acc: 0.452 - ETA: 0s - loss: 1.0829 - acc: 0.452 - ETA: 0s - loss: 1.0827 - acc: 0.452 - ETA: 0s - loss: 1.0824 - acc: 0.451 - ETA: 0s - loss: 1.0820 - acc: 0.452 - ETA: 0s - loss: 1.0816 - acc: 0.452 - ETA: 0s - loss: 1.0816 - acc: 0.452 - ETA: 0s - loss: 1.0817 - acc: 0.452 - ETA: 0s - loss: 1.0818 - acc: 0.452 - ETA: 0s - loss: 1.0813 - acc: 0.451 - 12s 337us/step - loss: 1.0813 - acc: 0.4519 - val_loss: 1.0692 - val_acc: 0.4611\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1577abf28>"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DNN (train)\n",
    "from tensorflow.keras.layers import Input, Dense, LSTM, BatchNormalization, Conv1D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, TensorBoard\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "# optunaでハイパーパラメタチューニングしてもよい\n",
    "input_length = 7\n",
    "batch_size = 32\n",
    "\n",
    "def create_model():\n",
    "    inputs = Input(shape=(input_length, 1))\n",
    "    x = LSTM(100, activation='relu')(inputs)\n",
    "#     x = BatchNormalization()(x)\n",
    "#     x = LSTM(100, activation='relu')(x)\n",
    "    outputs = Dense(4, activation='softmax')(x)\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def create_data(data):\n",
    "    x = []\n",
    "    y = []\n",
    "    label = np.eye(4)\n",
    "    for i in range(input_length, len(data)):\n",
    "        base = data[i-1]\n",
    "        x.append((data[i-input_length:i] - base) / base)\n",
    "        if (data[i] - base) / base >= 0.005:\n",
    "            y.append(label[0])\n",
    "        elif (data[i] - base) / base >= 0:\n",
    "            y.append(label[1])\n",
    "        elif (data[i] - base) / base >= -0.005:\n",
    "            y.append(label[2])\n",
    "        else:\n",
    "            y.append(label[3])\n",
    "    x = np.asarray(x).reshape((-1, input_length, 1))  # for LSTM\n",
    "    y = np.asarray(y).reshape((-1, 4))\n",
    "    return x, y\n",
    "\n",
    "def sign_accuracy(y_true, y_pred):\n",
    "    return K.equal(K.sign(K.get_value(K.argmax(y_true) - 1.5)), K.sign(K.get_value(K.argmax(y_pred) - 1.5)))\n",
    "    \n",
    "\n",
    "# optimize\n",
    "model = create_model()\n",
    "train, _ = split_train_test(v)\n",
    "x, y = create_data(train)\n",
    "x_train, x_val, y_train, y_val = train_test_split(x, y, test_size=0.25, shuffle=True)\n",
    "es_cb = EarlyStopping(monitor='val_loss', patience=0, verbose=0, mode='auto')\n",
    "tb_cb = TensorBoard(log_dir=\"tflog/\", histogram_freq=1)\n",
    "model.fit(x_train, y_train, validation_data=(x_val, y_val), epochs=100, batch_size=batch_size, callbacks=[es_cb])\n",
    "# model.save('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "382 : BUY\n",
      "390 : CLOSE, profit=-0.02506865671641791\n",
      "394 : BUY\n",
      "395 : CLOSE, profit=-0.027426367823277092\n",
      "395 : SELL\n",
      "398 : CLOSE, profit=0.002871713826239769\n",
      "398 : BUY\n",
      "401 : CLOSE, profit=0.031706577604901934\n",
      "454 : BUY\n",
      "455 : CLOSE, profit=0.034176873311447004\n",
      "455 : SELL\n",
      "456 : CLOSE, profit=0.03554253374742277\n",
      "456 : BUY\n",
      "459 : CLOSE, profit=0.040950160734426345\n",
      "472 : BUY\n",
      "473 : CLOSE, profit=0.08676360611257761\n",
      "830 : BUY\n",
      "837 : CLOSE, profit=0.09880911323805319\n",
      "851 : SELL\n",
      "852 : CLOSE, profit=0.0984636906912873\n",
      "873 : SELL\n",
      "874 : CLOSE, profit=0.10055602563182905\n",
      "874 : BUY\n",
      "876 : CLOSE, profit=0.11440390761905728\n",
      "883 : BUY\n",
      "889 : CLOSE, profit=0.1231335372486869\n",
      "912 : SELL\n",
      "913 : CLOSE, profit=0.14097254010308186\n",
      "913 : BUY\n",
      "925 : CLOSE, profit=0.10982718998585467\n",
      "925 : SELL\n",
      "926 : CLOSE, profit=0.12948369405089533\n",
      "926 : BUY\n",
      "929 : CLOSE, profit=0.14492068592081403\n",
      "929 : SELL\n",
      "936 : CLOSE, profit=0.15001865176404053\n",
      "952 : SELL\n",
      "959 : CLOSE, profit=0.14624936838384447\n",
      "962 : BUY\n",
      "965 : CLOSE, profit=0.14244005209580723\n",
      "965 : SELL\n",
      "967 : CLOSE, profit=0.145635497361807\n",
      "973 : BUY\n",
      "977 : CLOSE, profit=0.15224059474750865\n",
      "1046 : SELL\n",
      "1048 : CLOSE, profit=0.1519298563454211\n",
      "1178 : SELL\n",
      "1180 : CLOSE, profit=0.15883639896159962\n",
      "1180 : BUY\n",
      "1188 : CLOSE, profit=0.13872434847068124\n",
      "1188 : SELL\n",
      "1189 : CLOSE, profit=0.14123826061695752\n",
      "1362 : BUY\n",
      "1370 : CLOSE, profit=0.10581799546969087\n",
      "1387 : BUY\n",
      "1388 : CLOSE, profit=0.10777907557227044\n",
      "1388 : SELL\n",
      "1390 : CLOSE, profit=0.10666328569005905\n",
      "1413 : BUY\n",
      "1416 : CLOSE, profit=0.13316507895059632\n",
      "1417 : SELL\n",
      "1424 : CLOSE, profit=0.1330900028187063\n",
      "1435 : SELL\n",
      "1436 : CLOSE, profit=0.12952044277114388\n",
      "1458 : SELL\n",
      "1464 : CLOSE, profit=0.13612612585526043\n",
      "1466 : BUY\n",
      "1469 : CLOSE, profit=0.1560784884929938\n",
      "1503 : SELL\n",
      "1504 : CLOSE, profit=0.1511990665168279\n",
      "1525 : SELL\n",
      "1526 : CLOSE, profit=0.1663439949044629\n",
      "1526 : BUY\n",
      "1529 : CLOSE, profit=0.1689335544208591\n",
      "1529 : SELL\n",
      "1530 : CLOSE, profit=0.16775367142592276\n",
      "1533 : SELL\n",
      "1534 : CLOSE, profit=0.17136979285808066\n",
      "1534 : BUY\n",
      "1536 : CLOSE, profit=0.20936562152441257\n",
      "1539 : SELL\n",
      "1541 : CLOSE, profit=0.22152091009787694\n",
      "1551 : BUY\n",
      "1553 : CLOSE, profit=0.23806051970305186\n",
      "1553 : SELL\n",
      "1554 : CLOSE, profit=0.25441559202650327\n",
      "1554 : BUY\n",
      "1555 : CLOSE, profit=0.2588595631358501\n",
      "1555 : SELL\n",
      "1556 : CLOSE, profit=0.252226425213978\n",
      "1600 : SELL\n",
      "1601 : CLOSE, profit=0.2463939781251715\n",
      "1679 : SELL\n",
      "1684 : CLOSE, profit=0.24825268968213904\n",
      "1713 : SELL\n",
      "1721 : CLOSE, profit=0.24811766858509263\n",
      "1749 : SELL\n",
      "1750 : CLOSE, profit=0.24626182654901657\n",
      "1751 : SELL\n",
      "1752 : CLOSE, profit=0.2388455681183588\n",
      "1808 : BUY\n",
      "1813 : CLOSE, profit=0.25558674412350607\n",
      "1833 : SELL\n",
      "1835 : CLOSE, profit=0.24915210550979033\n",
      "1881 : SELL\n",
      "1882 : CLOSE, profit=0.2453294642627748\n",
      "1894 : BUY\n",
      "1899 : CLOSE, profit=0.22628167969738927\n",
      "1899 : SELL\n",
      "1900 : CLOSE, profit=0.2326558194113999\n",
      "1992 : SELL\n",
      "1999 : CLOSE, profit=0.22465145108347054\n",
      "2087 : SELL\n",
      "2088 : CLOSE, profit=0.21901718647148413\n",
      "2149 : SELL\n",
      "2150 : CLOSE, profit=0.22588254738216978\n",
      "2150 : BUY\n",
      "2153 : CLOSE, profit=0.22927733461170688\n",
      "2153 : SELL\n",
      "2154 : CLOSE, profit=0.2304761433650125\n",
      "2201 : BUY\n",
      "2205 : CLOSE, profit=0.22956774272362657\n",
      "2205 : SELL\n",
      "2207 : CLOSE, profit=0.2333358920667932\n",
      "2400 : BUY\n",
      "2408 : CLOSE, profit=0.2396030726216209\n",
      "2487 : BUY\n",
      "2500 : CLOSE, profit=0.2434016493886374\n",
      "2524 : BUY\n",
      "2531 : CLOSE, profit=0.21287850926411078\n",
      "2531 : SELL\n",
      "2532 : CLOSE, profit=0.20907142275380816\n",
      "2589 : SELL\n",
      "2590 : CLOSE, profit=0.22626086099587797\n",
      "2590 : BUY\n",
      "2593 : CLOSE, profit=0.2244642170939709\n",
      "2593 : SELL\n",
      "2594 : CLOSE, profit=0.22803296342792004\n",
      "2601 : SELL\n",
      "2607 : CLOSE, profit=0.24078006008331967\n",
      "2608 : BUY\n",
      "2612 : CLOSE, profit=0.2549599947191574\n",
      "2712 : SELL\n",
      "2717 : CLOSE, profit=0.27190941207479835\n",
      "3182 : BUY\n",
      "3184 : CLOSE, profit=0.2697466653865042\n",
      "3184 : SELL\n",
      "3185 : CLOSE, profit=0.2628800267030046\n",
      "3533 : SELL\n",
      "3539 : CLOSE, profit=0.2588382512460855\n",
      "3736 : SELL\n",
      "3737 : CLOSE, profit=0.24795016473812864\n",
      "3806 : SELL\n",
      "3815 : CLOSE, profit=0.2246444472604997\n",
      "3855 : BUY\n",
      "3859 : CLOSE, profit=0.2393468874938295\n",
      "3948 : BUY\n",
      "3950 : CLOSE, profit=0.24393357854742498\n",
      "3950 : SELL\n",
      "3951 : CLOSE, profit=0.2546306044375001\n",
      "3951 : BUY\n",
      "3955 : CLOSE, profit=0.2695296099057647\n",
      "4160 : SELL\n",
      "4166 : CLOSE, profit=0.27050353047713144\n",
      "4220 : SELL\n",
      "4221 : CLOSE, profit=0.2633319928914825\n",
      "4222 : BUY\n",
      "4223 : CLOSE, profit=0.26374150423761755\n",
      "4223 : SELL\n",
      "4224 : CLOSE, profit=0.26361248862672865\n",
      "4254 : BUY\n",
      "4259 : CLOSE, profit=0.2561985412706991\n",
      "4259 : SELL\n",
      "4260 : CLOSE, profit=0.25748104624040585\n",
      "4521 : BUY\n",
      "4541 : CLOSE, profit=0.2546843783981121\n",
      "4603 : SELL\n",
      "4609 : CLOSE, profit=0.2565051966563613\n",
      "4732 : BUY\n",
      "4739 : CLOSE, profit=0.2586443427885963\n"
     ]
    }
   ],
   "source": [
    "# DNN (test)\n",
    "_, test = split_train_test(v)\n",
    "x_test, y_test = create_data(test)\n",
    "pred = model.predict(x_test)\n",
    "actual = test[input_length-1:-1]\n",
    "\n",
    "# simulation\n",
    "profit = 0.0  # 利益\n",
    "position = 0  # -1 : 売りポジ, 0 : ポジなし, 1 : 買いポジ\n",
    "p_price = 0.0  # ポジションの額\n",
    "for i in range(len(pred)):\n",
    "    if position < 0 and np.argmax(pred[i]) <= 1:  # 売りポジclose\n",
    "        profit += (p_price - actual[i]) / actual[i]\n",
    "        position = 0\n",
    "        print ('{0} : CLOSE, profit={1}'.format(i, profit))\n",
    "    if position > 0 and np.argmax(pred[i]) >= 2:  # 買いポジclose\n",
    "        profit += (actual[i] - p_price) / p_price\n",
    "        position = 0\n",
    "        print ('{0} : CLOSE, profit={1}'.format(i, profit))\n",
    "    if position == 0 and np.argmax(pred[i]) == 3:  # 売り\n",
    "        p_price = actual[i]\n",
    "        position = -1        \n",
    "        print ('{0} : SELL'.format(i))\n",
    "    if position == 0 and np.argmax(pred[i]) == 0:  # 買い\n",
    "        p_price = actual[i]\n",
    "        position = +1\n",
    "        print ('{0} : BUY'.format(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4444 samples, validate on 1482 samples\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-119-2079a29a3901>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0mes_cb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEarlyStopping\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmonitor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'auto'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0mtb_cb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTensorBoard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"tflog/\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhistogram_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mes_cb\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0;31m# model.save('model.h5')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1361\u001b[0m           \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1362\u001b[0m           \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1363\u001b[0;31m           validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1365\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    262\u001b[0m           \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 264\u001b[0;31m         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    265\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m           \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2874\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'`inputs` should be a list or tuple.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2875\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2876\u001b[0;31m     \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2877\u001b[0m     \u001b[0mfeed_arrays\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2878\u001b[0m     \u001b[0marray_vals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36mget_session\u001b[0;34m()\u001b[0m\n\u001b[1;32m    442\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_MANUAL_VAR_INIT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 444\u001b[0;31m       \u001b[0m_initialize_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    445\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m_initialize_variables\u001b[0;34m(session)\u001b[0m\n\u001b[1;32m    666\u001b[0m     \u001b[0;31m# marked as initialized.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    667\u001b[0m     is_initialized = session.run(\n\u001b[0;32m--> 668\u001b[0;31m         [variables_module.is_variable_initialized(v) for v in candidate_vars])\n\u001b[0m\u001b[1;32m    669\u001b[0m     \u001b[0muninitialized_vars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    670\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mflag\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_initialized\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcandidate_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    875\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    876\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 877\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    878\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1098\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1099\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1100\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1101\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1270\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1271\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1272\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1273\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1274\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1276\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1277\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1278\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1279\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1280\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1261\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1262\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1263\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1265\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1348\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1349\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1350\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# DNN (train all features)\n",
    "from tensorflow.keras.layers import Input, Dense, LSTM, BatchNormalization\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, TensorBoard\n",
    "from tensorflow.keras import backend as K\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# optunaでハイパーパラメタチューニングしてもよい\n",
    "input_length = 7\n",
    "batch_size = 64\n",
    "\n",
    "def create_model():\n",
    "    inputs = Input(shape=(input_length, v_all.shape[1]))\n",
    "    x = BatchNormalization()(inputs)\n",
    "    x = LSTM(500, activation='relu')(x)\n",
    "    outputs = Dense(1, activation='linear')(x)\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    model.compile(loss='mse', optimizer='adam', metrics=[sign_accuracy])\n",
    "    return model\n",
    "\n",
    "def create_data(data):\n",
    "    x = []\n",
    "    y = []\n",
    "    for i in range(input_length, len(data)):\n",
    "        x_tmp = deepcopy(data[i-input_length:i])\n",
    "        x_tmp[:,:-1] = (x_tmp[:,:-1] - x_tmp[-1, 3]) / x_tmp[-1, 3]  # ohlc 騰落率\n",
    "        x_tmp[:,-1] = (x_tmp[:,-1] - np.min(x_tmp[:,-1])) / (np.max(x_tmp[:,-1]) - np.min(x_tmp[:,-1]) + 0.001)  # volume 0-1scaling\n",
    "        x.append(x_tmp)\n",
    "        y.append((data[i,3] - data[i-1,3]) / data[i-1,3])\n",
    "    x = np.asarray(x).reshape((-1, input_length, data.shape[1]))  # for LSTM\n",
    "    y = np.asarray(y).reshape((-1, 1))\n",
    "    return x, y\n",
    "\n",
    "def sign_accuracy(y_true, y_pred):\n",
    "    return K.equal(K.sign(y_true), K.sign(y_pred))\n",
    "    \n",
    "\n",
    "# optimize\n",
    "model = create_model()\n",
    "train, _ = split_train_test(v_all)\n",
    "x, y = create_data(train)\n",
    "x_train, x_val, y_train, y_val = train_test_split(x, y, test_size=0.25, shuffle=True)\n",
    "es_cb = EarlyStopping(monitor='val_loss', patience=0, verbose=0, mode='auto')\n",
    "tb_cb = TensorBoard(log_dir=\"tflog/\", histogram_freq=1)\n",
    "model.fit(x_train, y_train, validation_data=(x_val, y_val), epochs=100, batch_size=batch_size, callbacks=[es_cb])\n",
    "# model.save('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
